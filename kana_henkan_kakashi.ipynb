{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCXyyDmHPJ94"
      },
      "source": [
        "# README\n",
        "**方言コーパスは個人利用にとどめることを強く推奨します。**\n",
        "**本プログラムの商用利用はご遠慮ください。**\n",
        "学術**論文**での利用を希望される場合、[Bandolu (Kogane)](https://github.com/Bandolu)までご連絡ください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojc1r8N3Laut"
      },
      "source": [
        "#このプログラムについて\n",
        "方言コーパスを平仮名に変換します。\n",
        "標準語の漢字入力も平等に平仮名に変えます。\n",
        "\n",
        "方言を平仮名にした後漢字に変換し直す労力を割ける人は[関数定義](https://colab.research.google.com/drive/1XxFAiD2lK-kExoEK5VwQUkwCvWGaUX5N?authuser=2#scrollTo=jtEwt4a327y3&line=1&uniqifier=1)セルを上手くイジってください。  \n",
        "Driveマウントの項はご自由にいじってどうぞ。\n",
        "\n",
        "##CSVフォーマット\n",
        "[ここ](https://www2.ninjal.ac.jp/cojads/index.html?targ=data)からコーパスをDLして、列を絞ってください。  \n",
        "再配布はしたくないので、結合作業は自分で頑張ってください。Excelがあれば簡単にできます。  \n",
        "\n",
        "|  話者  |  地名  |  方言テキスト  |  標準語テキスト  |\n",
        "| ---- | ---- | ---- | ---- |\n",
        "|  TD  |  TD  | TD  |  TD  |\n",
        "|  TD  |  TD  | TD  |  TD  |\n",
        "\n",
        "\n",
        "### 参考にさせていただきました\n",
        "[Python] 結合文字を使用した濁点や半濁点を直前の仮名と結合させる方法(ウ゛→ ヴ) - Qiita https://qiita.com/gretchi/items/13c0825282415e2e360d\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbb70jrW8h3u"
      },
      "source": [
        "#Driveマウント"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HD2eueDpC7oE",
        "outputId": "bebd8e34-5b10-43d0-f078-95c7a3594d46",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coo9YpA9cdWA",
        "outputId": "960acd86-dadd-4f3e-dcd8-e222f8ae3183",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks/Transformer\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/My\\ Drive/Colab\\ Notebooks/Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epQKzhSr2eQp"
      },
      "source": [
        "# ライブラリ読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3fHswsx2Ur8",
        "outputId": "ef9fe409-f47a-45f7-d5ef-ab1e8557d9ad",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jaconv\n",
            "  Downloading jaconv-0.3.4.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Building wheels for collected packages: jaconv\n",
            "  Building wheel for jaconv (setup.py): started\n",
            "  Building wheel for jaconv (setup.py): finished with status 'done'\n",
            "  Created wheel for jaconv: filename=jaconv-0.3.4-py3-none-any.whl size=16417 sha256=8c00702f97a9680e5daabbdb26211eabda3d73d1c68f046761224a3b75fdf05b\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/5f/db/745dae56064ecb90a09a5d5aad9f0f2993becb640264dc36ba\n",
            "Successfully built jaconv\n",
            "Installing collected packages: jaconv\n",
            "Successfully installed jaconv-0.3.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting icecream\n",
            "  Downloading icecream-2.1.3-py2.py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.8/dist-packages (from icecream) (2.6.1)\n",
            "Collecting executing>=0.3.1\n",
            "  Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting colorama>=0.3.9\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting asttokens>=2.0.1\n",
            "  Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from asttokens>=2.0.1->icecream) (1.15.0)\n",
            "Installing collected packages: executing, colorama, asttokens, icecream\n",
            "Successfully installed asttokens-2.2.1 colorama-0.4.6 executing-1.2.0 icecream-2.1.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pykakasi\n",
            "  Downloading pykakasi-2.2.1-py3-none-any.whl (2.4 MB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.4/2.4 MB 27.1 MB/s eta 0:00:00\n",
            "Requirement already satisfied: jaconv in /usr/local/lib/python3.8/dist-packages (from pykakasi) (0.3.4)\n",
            "Collecting deprecated\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.8/dist-packages (from deprecated->pykakasi) (1.14.1)\n",
            "Installing collected packages: deprecated, pykakasi\n",
            "Successfully installed deprecated-1.2.13 pykakasi-2.2.1\n"
          ]
        }
      ],
      "source": [
        "%%bash \n",
        "pip install  jaconv\n",
        "pip install icecream\n",
        "pip install pykakasi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4JgjJzs4MGb",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import codecs\n",
        "import copy\n",
        "import jaconv\n",
        "import os\n",
        "from icecream import ic\n",
        "import unicodedata\n",
        "from pykakasi import kakasi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mOaAw5S-1TP"
      },
      "source": [
        "###デバッグ不要なら以下のセルを起動すべし。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtg9FpCh-0rp",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "ic.disable()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGuSp62c2o4x"
      },
      "source": [
        "# データ読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "snWWm2Jp2c4p",
        "outputId": "2a49fea5-d4ab-4b5d-eaa9-28c3c6b0f89b",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "in_file = \"0001_sendai_v1_utf8.csv\"\n",
        "corpus_path = os.path.join(\"DATA\",in_file)\n",
        "df = pd.read_csv(corpus_path)\n",
        "#df['A'] = \"\"\n",
        "ic('**** Amount of data ****')\n",
        "ic(df)\n",
        "ic('\\n')\n",
        "ic('**** Amount of data ****')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtEwt4a327y3"
      },
      "source": [
        "# 関数定義"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLrTWnl4JeiN",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "# オブジェクトをインスタンス化\n",
        "kakasi = kakasi()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9yQpwxKHnSd",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "#c_path = './DATA/Kessen.txt'\n",
        "\n",
        "c_df = copy.deepcopy(df)\n",
        "pHogen = re.compile(r'[（ＦF：）ＤＺＭ〔〕＊［］Ｏ１ＳＧＣＰＬＲX123SP＜＞＝｛｝「」]')\n",
        "pGroup = re.compile(r'(DM|Z|X|SG|〔[0-9]{1,2}〕)')\n",
        "pEq = re.compile(r'＝(.*?)＞')\n",
        "\n",
        "\n",
        "def kata_hira(x):\n",
        "    return jaconv.kata2hira(x)\n",
        "\n",
        "def regexEqrm(x):\n",
        "    return re.sub(pEq, '＞', x)\n",
        "\n",
        "def regexRm(x):\n",
        "    return re.sub(pHogen, '', x)\n",
        "\n",
        "def regexGr(x):\n",
        "    return re.sub(pGroup, '', x)\n",
        "\n",
        "\n",
        "def noma(x):\n",
        "    return unicodedata.normalize('NFKC', x)\n",
        "\n",
        "def join_diacritic(_text):\n",
        "    \"\"\"\n",
        "    基底文字と濁点・半濁点を結合\n",
        "    \"\"\"\n",
        "\n",
        "    # 謎の○を濁点に戻す\n",
        "    text = re.sub('゜', '゛', _text)\n",
        "    # str -> bytes\n",
        "    bytes_text = text.encode()\n",
        "\n",
        "\n",
        "\n",
        "    # 濁点Unicode結合文字置換\n",
        "    bytes_text = re.sub(b\"\\xe3\\x82\\x9b\", b'\\xe3\\x82\\x99', bytes_text)\n",
        "    bytes_text = re.sub(b\"\\xef\\xbe\\x9e\", b'\\xe3\\x82\\x99', bytes_text)\n",
        "\n",
        "    # 半濁点Unicode結合文字置換\n",
        "    bytes_text = re.sub(b\"\\xe3\\x82\\x9c\", b'\\xe3\\x82\\x9a', bytes_text)\n",
        "    bytes_text = re.sub(b\"\\xef\\xbe\\x9f\", b'\\xe3\\x82\\x9a', bytes_text)\n",
        "\n",
        "    # bytet -> str\n",
        "    text = bytes_text.decode()\n",
        "\n",
        "    # 正規化\n",
        "    mode=\"NFKC\"\n",
        "    text = unicodedata.normalize(mode, text)\n",
        "\n",
        "    return text\n",
        "\n",
        "\n",
        "def kanji2hiragana(x):\n",
        "    text = x\n",
        "\n",
        "    # モードの設定：J(Kanji) to H(Hiragana)\n",
        "    kakasi.setMode('J', 'H') \n",
        "\n",
        "    # 変換して出力\n",
        "    conv = kakasi.getConverter()\n",
        "    text = conv.do(text)  # => けいたいそかいせき\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2TkWOyfLRu5"
      },
      "source": [
        "#実行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWmFXO3nxGEe",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "hougen = c_df['方言テキスト']\n",
        "hyoujun = c_df['標準語テキスト']\n",
        "ic(hougen)\n",
        "ic(hyoujun)\n",
        "\n",
        "hougen = hougen.map(regexEqrm)\n",
        "hougen = hougen.map(regexGr)\n",
        "hougen = hougen.map(regexRm)\n",
        "hougen = hougen.map(join_diacritic)\n",
        "hougen = hougen.map(kata_hira)\n",
        "#ic(hougen)\n",
        "hyoujun = hyoujun.map(regexEqrm)\n",
        "hyoujun = hyoujun.map(regexGr)\n",
        "hyoujun = hyoujun.map(regexRm)\n",
        "hyoujun = hyoujun.map(kanji2hiragana)\n",
        "hyoujun = hyoujun.map(kata_hira)\n",
        "hyoujun = hyoujun.map(noma)\n",
        "#ic(hyoujun)\n",
        "        \n",
        "        #print(parsed,file=f)\n",
        "ic(c_df.head())\n",
        "\n",
        "c_df['方言テキスト'] = hougen\n",
        "c_df['標準語テキスト'] = hyoujun\n",
        "ic(c_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "id": "44zf_ACZdT-G",
        "outputId": "5a14a9ee-5d62-4d56-82c6-2b291f40024e",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "hougen = c_df['方言テキスト']\n",
        "hyoujun = c_df['標準語テキスト']\n",
        "ic(hougen)\n",
        "ic(hyoujun)\n",
        "\n",
        "hougen = hougen.map(regexEqrm)\n",
        "hougen = hougen.map(regexGr)\n",
        "hougen = hougen.map(regexRm)\n",
        "hougen = hougen.map(join_diacritic)\n",
        "hougen = hougen.map(kata_hira)\n",
        "#ic(hougen)\n",
        "\n",
        "hyoujun = hyoujun.map(regexEqrm)\n",
        "hyoujun = hyoujun.map(regexGr)\n",
        "hyoujun = hyoujun.map(regexRm)\n",
        "#hyoujun = hyoujun.map(kanji2hiragana)\n",
        "hyoujun = hyoujun.map(kata_hira)\n",
        "hyoujun = hyoujun.map(noma)\n",
        "#ic(hyoujun)\n",
        "        \n",
        "        #print(parsed,file=f)\n",
        "ic(c_df.head())\n",
        "\n",
        "c_df['方言テキスト'] = hougen\n",
        "c_df['標準語テキスト'] = hyoujun\n",
        "ic(c_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ThksbsYihrM",
        "outputId": "a059c852-22dc-42ff-c1e5-89358c9fab09",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ic| len(in_df): 16293\n",
            "ic| len(in_df2): 16293\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "16293"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "in_df = c_df.reindex(columns=['方言テキスト','標準語テキスト',  '地点','話者'])\n",
        "ic(len(in_df))\n",
        "in_df2 =in_df.dropna(how='any')\n",
        "ic(len(in_df2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4I9b0rET3AgC"
      },
      "source": [
        "# データ出力"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0BwBcADf99yq",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [],
      "source": [
        "in_df2.to_csv( os.path.join(\"DATA\",\"Katahira_\"+in_file), index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKsDdvqClQ1U"
      },
      "source": [
        "##内容がない行を削除"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "781IdmKjlX4g",
        "outputId": "77a3f5fa-3ad7-4caa-ef8f-8a900eb13730",
        "vscode": {
          "languageId": "python"
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ic| len(in_df): 16293\n",
            "ic| len(in_df2): 15014\n"
          ]
        }
      ],
      "source": [
        "in_file = \"0001_sendai_v1_utf8.csv\"\n",
        "corpus_path = os.path.join(\"DATA\",\"Katahira_\"+in_file)\n",
        "in_df = pd.read_csv(corpus_path)\n",
        "ic(len(in_df))\n",
        "in_df2 =in_df.dropna(how='any')\n",
        "ic(len(in_df2))\n",
        "in_df2.to_csv( os.path.join(\"DATA\",\"DR_Katahira_\"+in_file), index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
